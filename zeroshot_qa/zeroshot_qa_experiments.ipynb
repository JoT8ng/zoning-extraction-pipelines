{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5e10c98",
   "metadata": {},
   "source": [
    "# Zero shot QA experiment 1 - DistilBERT vs LEGAL-BERT\n",
    "## October 2025\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Zoning By-laws contain important information about land use, building height, density, and other development regulations. They are important documents that inform urban planning and development decisions in cities.\n",
    "\n",
    "They are often stored as long, unstructured PDF legal documents and it's difficult to find information within them. Zoning information is also spatial and tied to geospatial datasets. It would be great if the zoning information in the by-laws could be extracted in an efficient and automated way and joined with geospatial datasets.\n",
    "\n",
    "**This experiement aims to test out and evaluate the performance of DistilBERT and LEGAL-BERT question answering models to extract information from zoning by-laws.**\n",
    "\n",
    "### Why DistilBERT and LegalBERT\n",
    "DistilBERT is a distilled or lighter version of the BERT model that was developed by Google. Because it is 40% smaller it makes it 60% faster at NLP tasks like text classification, sentiment analysis, and question answering. Although, it is smaller it still retains 97% of BERT's accuracy. In the [Claude LLM API Pipeline](https://github.com/JoT8ng/zoning-extraction-pipelines/blob/main/llm_api_pipeline/src/README.md), Anthropic's Claude model was tested to extract information from zoning by-laws. One of the key limitations of using a model like Claude is that the generative component of the model is prone to hallucinations. **Unlike models like Claude and GPT, BERT is an encoder only model. This means it is good for tasks that require understanding of input like sentence classification or NER (named entity recognition).** For a task like extracting information from a zoning by-law, text generation is not that important. **LLMs like GPT and Claude who excel and are mainly used for generative tasks are not considered the most efficient at text classification and NER compared to bidirectional encoders like BERT. That is why a lighter version of BERT, DistilBERT, is chosen for this experiment.**\n",
    "\n",
    "There are many pre-trained models of BERT in the Hugging Face Transformer's library. [LEGAL-BERT](https://huggingface.co/nlpaueb/legal-bert-base-uncased) is a family of BERT models for the legal domain, intended to assist legal NLP research, computational law, and legal technology applications. LEGAL-BERT is pre-trained on 12 GB of diverse English legal text from several fields (e.g., legislation, court cases, contracts) scraped from publicly available resources. For more info on the data the model is pretrained on, refer to the model card on Hugging Face. **Since zoning by-law texts are legal documents, it would be interesting to compare the accuracy of DistilBERT vs LEGAL-BERT in this context**.\n",
    "\n",
    "For more info on NLP, LLMs, and transformer models:\n",
    "[Hugging Face LLM Course](https://huggingface.co/learn/llm-course/en/chapter1/2)\n",
    "\n",
    "### Why QA (question answering) models? Comparing different NLP tasks\n",
    "The table below compares the pros and cons of different NLP tasks for extracting zoning by-law information. Based on the table below, question answering seems to be the most appropriate.\n",
    "\n",
    "| Approach                           | What it does                                                                           | Pros                                                                                                                             | Cons                                                                                                                 |\n",
    "| ---------------------------------- | -------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Text Classification**            | Assigns a label to an entire chunk of text (e.g. \"this section contains height rules\") | Simple to set up, works well if zoning is neatly sectioned                                                                       | Can’t extract numeric values, only gives category                                                                    |\n",
    "| **NER (Named Entity Recognition)** | Finds predefined entities in text (e.g. `HEIGHT=9.1 m`, `LOT_COVERAGE=35%`)            | Good for structured outputs; works well if entity spans are clearly defined                                                      | Requires labeled token-level data, zoning text is irregular (tables, bullets, weird formatting), not great zero-shot |\n",
    "| **QA (Question Answering)**        | Extracts a text span from context given a natural-language question                    | Works very well zero-shot, doesn’t need special labeling format, flexible | Requires splitting long contexts, can hallucinate occasionally                                                      |\n",
    "\n",
    "### Imports and Set Up\n",
    "\n",
    "First, import all the necessary Python libraries. The Hugging Face Transformers Library is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209ee48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49c3528",
   "metadata": {},
   "source": [
    "The SQuAD metric is used to evaluate the accuracy of the models. Hugging Face's evaluate library provides squad metrics that can calculate exact Mmatch (EM) and token-level F1.\n",
    "\n",
    "SQuAD (Stanford Question Answering Dataset) is a metric widely used to evaluate and assess the performance of machine learning models. It is most often used for question answering and reading comprehension tasks.\n",
    "\n",
    "* **Exact Match (EM):** This metric measures the percentage of questions where the model's answer exactly matches one of the ground truth answers.\n",
    "* **F1 Score:** This metric calculates the overlap between the predicted answer and the ground truth answers. It considers both precision (the number of correct answers provided by the model) and recall (the number of correct answers that should have been provided). The F1 score is the harmonic mean of precision and recall, providing a balance between the two. A higher F1 score indicates a better performing model.\n",
    "\n",
    "**Reference:**\n",
    "\n",
    "Rajpurkar et al., \"*SQuAD: 100,000+ Questions for Machine Comprehension of Text*\", EMNLP 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061946c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SQuAD metrics\n",
    "squad_metric = evaluate.load(\"squad\")\n",
    "\n",
    "# Set up array to store LLM responses\n",
    "results = []\n",
    "\n",
    "# Evaluation helper function to prepare inputs for Hugging Face SQuAD metrics\n",
    "def evaluate_model(res, model):\n",
    "\n",
    "    # res or results: results dictionary containing the outputs of the LLMs/predictions and ground truth\n",
    "    # model: \"distil_answer\" or \"legal_answer\"\n",
    "\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for r in res:\n",
    "        predictions.append({\n",
    "            \"id\": str(r[\"doc_id\"]),\n",
    "            \"prediction_text\": r[model]\n",
    "        })\n",
    "        references.append({\n",
    "            \"id\": str(r[\"doc_id\"]),\n",
    "            \"answers\": {\n",
    "                \"text\": [r[\"ground_truth\"]],\n",
    "                \"answer_start\": [0]  # dummy value\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Compute metrics\n",
    "    return squad_metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bd9577",
   "metadata": {},
   "source": [
    "### Creating the evaluation dataset\n",
    "\n",
    "The functions in [Zoning PDF Text Extraction and Parsing Functions](https://github.com/JoT8ng/zoning-extraction-pipelines/tree/main/common_pdf_parsing) are used to extract text from a zoning by-law section. In the example below, the text from Burnaby's zoning by-law on R1 small scale multi unit housing is extracted. Unlike the Claude model, DistilBERT and LEGAL-BERT accept a smaller and more limited amount of tokens. Furthermore, the dataset had to be in a specific format containing the \"context\", \"question\", and \"ground truth\" for evaluating the model. Therefore, the chunks of text to be input as the \"context\" into the model had to be manually extracted.\n",
    "\n",
    "To really test the efficacy of the models in extracting the zoning information, a range of different questions and contexts are used. Some of the contexts are a mix of messy and clean snippets from the zoning by-law. One context contains a longer and messy snippet of raw text directly extracted from the pdf and another contains a similar long and messy snippet in raw markdown syntax. Snippets of tables in markdown syntax are also included. To challenge the model, sometimes a context is provided that does not contain the answer to the question. In that scenario, the model is required to respond that there is no answer specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc73870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small labeled evaluation dataset\n",
    "dataset = [\n",
    "    {\n",
    "        \"doc_id\": 1,\n",
    "        \"context\": \"\"\"\n",
    "        Maximum Height:       \n",
    "        Principal Building \n",
    "        12.0 m | 4 storeys,    \n",
    "        Accessory Buildings \n",
    "        4.0 m | 1 storey \n",
    "        \"\"\",\n",
    "        \"question\": \"What is the maximum building height for accessory buildings?\",\n",
    "        \"ground_truth\": \"4.0 m\"\n",
    "    },\n",
    "    {\n",
    "        \"doc_id\": 2,\n",
    "        \"context\": \"\"\"\n",
    "        Rowhouse Maximum Lot Area:\n",
    "        1-3 units: 280m2\n",
    "        Small-Scale Multi-Unit Maximum Lot Area:\n",
    "        1-3 units: -,\n",
    "        4 units: -,\n",
    "        5-6 units: -\n",
    "        \"\"\",\n",
    "        \"question\": \"What is the maximum lot area for 5-6 small-scale multi-units?\",\n",
    "        \"ground_truth\": \"not specified\"\n",
    "    },\n",
    "    {\n",
    "        \"doc_id\": 3,\n",
    "        \"context\": \"\"\"\n",
    "        A child care facility in the R1 District must:\n",
    "        (a) be limited to a maximum of 25 children;\n",
    "        (b) be located on a corner lot;\n",
    "        (c) comply with the development regulations under section 101.4 for 1 to 3 small-scale multi-unit dwelling units on a lot;\n",
    "        (d) be located on a lot that does not contain a dwelling unit or any other principal use; and\n",
    "        (e) comply with all other applicable regulations under this Bylaw.\n",
    "        \"\"\",\n",
    "        \"question\": \"Where does a child care facility in the R1 district be located?\",\n",
    "        \"ground_truth\": \"be located on a corner lot\"\n",
    "    },\n",
    "    {\n",
    "        \"doc_id\": 4,\n",
    "        \"context\": \"\"\"\n",
    "        some or all of the following regulations may apply to lots in the R1 District on the Community Heritage Register:\n",
    "        (a) panhandle lots and other irregularly shaped lots may be permitted subject to the following:\n",
    "            (i) lots with lane access shall have a minimum panhandle width of 1 m that is clear to a height of 2.5 m; and\n",
    "            (ii) lots without lane access shall have a minimum panhandle width of 4.5 m that is clear to a height of 2.5 m;\n",
    "        (b) maximum lot coverage as set out in Section 101.4 may be increased to up to 60%;\n",
    "        (c) all original architectural appurtenances, such as chimneys, railings, vents, decorative features, or similar, may be excluded from the maximum permitted height of a principal building;\n",
    "        (d) lot line setbacks for street yards may meet a minimum of 2.0 m;\n",
    "        (e) the minimum separation between buildings on the same lot as required under Section 101.4 may be reduced;\n",
    "        \"\"\",\n",
    "        \"question\": \"For lots in the R1 district on the Community Heritage Register, what is the minimum lot line setback for street yards?\",\n",
    "        \"ground_truth\": \"2.0 m\"\n",
    "    },\n",
    "    {\n",
    "        \"doc_id\": 5,\n",
    "        \"context\": \"\"\"\n",
    "        **Dwelling Type**\n",
    "        **Rowhouse[ .1]** **Small-Scale Multi-Unit**\n",
    "\n",
    "        Minimum Lot Width[ .2]\n",
    "\n",
    "        5 m, except 6.2 m for end unit\n",
    "        Interior Lot 10 m\n",
    "\n",
    "        lots\n",
    "\n",
    "        Corner Lot - Street 8 m 10 m\n",
    "\n",
    "        Corner Lot - Lane 6.2 m 10 m\n",
    "\n",
    "        Lot Area[ .3]\n",
    "\n",
    "        Minimum Lot Area       - 281 m[2]\n",
    "\n",
    "        Maximum Lot Area 280 m[2]       \n",
    "        .1 At the time of registration of the subdivision plan to create two or more rowhouse lots, the\n",
    "        registration of a Section 219 Covenant will be required to ensure that all adjoining rowhouse\n",
    "        dwellings will be constructed at the same time.\n",
    "\n",
    "        |Permitted Uses|Col2|\n",
    "        |---|---|\n",
    "        |Principal Use|Use-Specific Regulations|\n",
    "        |Small-Scale Multi-Unit Housing|-|\n",
    "        |Rowhouse Dwellings|101.5.2|\n",
    "        |Boarding, Lodging, or Rooming House|101.5.3|\n",
    "        |Group Home|-|\n",
    "        |Supportive Housing (Category A)|101.5.4|\n",
    "        |Child Care Facilities|101.5.6|\n",
    "        |Accessory Use|Use-Specific Regulations|\n",
    "        |Boarding Use (up to 2 boarders)|-|\n",
    "        |Home Occupations|6.8, 6.8A|\n",
    "        |Urban Agriculture|6.30|\n",
    "        |Accessory Buildings, Structures, and Uses|101.5.5, 6.6|\n",
    "        \"\"\",\n",
    "        \"question\": \"What is the minimum lot width for a rowhouse that has a street corner lot?\",\n",
    "        \"ground_truth\": \"Corner Lot - Street 8 m\"\n",
    "    },\n",
    "    {\n",
    "        \"doc_id\": 6,\n",
    "        \"context\": \"\"\"\n",
    "        The minimum number of dwelling units with at least 3 bedrooms must be provided on a lot as follows:\n",
    "        |Col1|Total Dwelling Units on a Lot|Col3|\n",
    "        |---|---|---|\n",
    "        ||1 to 3 Units|4 to 6 Units|\n",
    "        |Minimum 3+ Bedroom Units:|1 Unit|2 Units|\n",
    "        \"\"\",\n",
    "        \"question\": \"What is the total number of dwelling units permitted on a lot for 1 to 3 units?\",\n",
    "        \"ground_truth\": \"Minimum 3+ Bedroom Units: 1 Unit\"\n",
    "    },\n",
    "    {\n",
    "        \"doc_id\": 7,\n",
    "        \"context\": \"\"\"\n",
    "        101.6 General Regulations 101.6.1 Projections (1) The following features may project into the required minimum separation between buildings on the same lot: (a) steps and stairs; \n",
    "        (b) ornamental features, such as arbors, trellises, fish ponds, flag poles, or similar landscape features; \n",
    "        (c) terraces, decks, or other similar surfaces that are 1.0 m or less above grade; \n",
    "        (d) balconies, covered decks, uncovered decks, canopies, sunshades, or other similar features, including supporting structures, that are greater than 1.0 m above grade up to a maximum of 25 percent of the width of a required separation; \n",
    "        (e) belt courses, cornices, gutters, sills, chimneys, bay windows, or other similar features up to the lesser of 0.9 m or 25 percent of the width of a required separation; \n",
    "        (f) sunken access areas and window wells as per Section 6.9; \n",
    "        (g) outdoor appliances; and \n",
    "        (h) eaves up to the lesser of 1.2 m (3.94 ft.) or 25 percent of the width of a required separation.\n",
    "        (2) Permitted projections into required yards are subject to Section 6.12, except that in the R1 District projections into required rear or side yards are limited to a maximum of 0.5 m where the rear or side yard abuts a lane to provide adequate fire truck clearance. \n",
    "\n",
    "        101.6.2 Outdoor Areas (1) An outdoor amenity space with a minimum width of 2.0 m and area of 10.0 m2 must be provided for each primary dwelling unit for its exclusive use and be directly accessible from the primary dwelling unit it serves.  \n",
    "        \n",
    "        101.6.3 Access and Fire Safety (1) Dwelling units located more than 45 m from a lot line abutting a street shall contain an automatic sprinkler system. \n",
    "        (2) All dwelling units shall have a minimum 1.0 m paved or gravel fire access corridor that: (a) provides direct pedestrian access from the dwelling unit entrance to a lot line abutting a street, or abutting a constructed lane where direct access to a street is not feasible; and \n",
    "        (b) is clear of any projections or obstructions to a minimum of 2.5 m in height.\n",
    "        \"\"\",\n",
    "        \"question\": \"What is the minimum width and area for outdoor amenity space for each primary dwelling unit?\",\n",
    "        \"ground_truth\": \"An outdoor amenity space with a minimum width of 2.0 m and area of 10.0 m2\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852c96ab",
   "metadata": {},
   "source": [
    "### Running and testing the models\n",
    "\n",
    "The Hugging Face Transformers pipeline function is used. Since these are simple experiments the pipeline function is deemed adequate and there doesn't need to be more custom adjustments of tokenizers etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2233df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load QA Pipelines for each model\n",
    "# DistilBERT\n",
    "distilbert_qa = pipeline(\n",
    "    \"question-answering\",\n",
    "    model = \"distilbert-base-uncased-distilled-squad\"\n",
    ")\n",
    "\n",
    "# LEGAL-BERT\n",
    "legalbert_qa = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=\"nlpaueb/legal-bert-small-uncased\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be6357",
   "metadata": {},
   "source": [
    "The results of the zero shot classification are saved in an array called \"results\". The results are output in the data frame below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df487a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>distil_answer</th>\n",
       "      <th>legal_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the maximum building height for access...</td>\n",
       "      <td>4.0 m</td>\n",
       "      <td>4.0 m | 1 storey</td>\n",
       "      <td>Accessory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What is the maximum lot area for 5-6 small-sca...</td>\n",
       "      <td>not specified</td>\n",
       "      <td>280m2</td>\n",
       "      <td>Area:\\n        1-3 units</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Where does a child care facility in the R1 dis...</td>\n",
       "      <td>be located on a corner lot</td>\n",
       "      <td>on a corner lot</td>\n",
       "      <td>be located on a lot that does not contain a dw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>For lots in the R1 district on the Community H...</td>\n",
       "      <td>2.0 m</td>\n",
       "      <td>2.0 m</td>\n",
       "      <td>access shall have a minimum panhandle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>What is the minimum lot width for a rowhouse t...</td>\n",
       "      <td>Corner Lot - Street 8 m</td>\n",
       "      <td>280 m</td>\n",
       "      <td>Boarding Use (up to 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>What is the total number of dwelling units per...</td>\n",
       "      <td>Minimum 3+ Bedroom Units: 1 Unit</td>\n",
       "      <td>Col1</td>\n",
       "      <td>be provided on a lot as follows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>What is the minimum width and area for outdoor...</td>\n",
       "      <td>An outdoor amenity space with a minimum width ...</td>\n",
       "      <td>2.0 m</td>\n",
       "      <td>provided for each primary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                           question  \\\n",
       "0       1  What is the maximum building height for access...   \n",
       "1       2  What is the maximum lot area for 5-6 small-sca...   \n",
       "2       3  Where does a child care facility in the R1 dis...   \n",
       "3       4  For lots in the R1 district on the Community H...   \n",
       "4       5  What is the minimum lot width for a rowhouse t...   \n",
       "5       6  What is the total number of dwelling units per...   \n",
       "6       7  What is the minimum width and area for outdoor...   \n",
       "\n",
       "                                        ground_truth     distil_answer  \\\n",
       "0                                              4.0 m  4.0 m | 1 storey   \n",
       "1                                      not specified             280m2   \n",
       "2                         be located on a corner lot   on a corner lot   \n",
       "3                                              2.0 m             2.0 m   \n",
       "4                            Corner Lot - Street 8 m             280 m   \n",
       "5                   Minimum 3+ Bedroom Units: 1 Unit              Col1   \n",
       "6  An outdoor amenity space with a minimum width ...             2.0 m   \n",
       "\n",
       "                                        legal_answer  \n",
       "0                                          Accessory  \n",
       "1                           Area:\\n        1-3 units  \n",
       "2  be located on a lot that does not contain a dw...  \n",
       "3              access shall have a minimum panhandle  \n",
       "4                              Boarding Use (up to 2  \n",
       "5                    be provided on a lot as follows  \n",
       "6                          provided for each primary  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run zero shot qa for DistilBERT and LEGAL-BERT to compare\n",
    "\n",
    "for data in dataset:\n",
    "    q = data['question']\n",
    "    ctext = data['context']\n",
    "    truth = data['ground_truth']\n",
    "\n",
    "    # DistilBERT\n",
    "    distil_response = distilbert_qa(question=q, context=ctext)['answer']\n",
    "    # LEGAL-BERT\n",
    "    legal_response = legalbert_qa(question=q, context=ctext)['answer']\n",
    "\n",
    "    results.append({\n",
    "        \"doc_id\": data['doc_id'],\n",
    "        \"question\": q,\n",
    "        \"ground_truth\": truth,\n",
    "        \"distil_answer\": distil_response,\n",
    "        \"legal_answer\": legal_response\n",
    "    })\n",
    "\n",
    "dataframe = pd.DataFrame(results)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e1add",
   "metadata": {},
   "source": [
    "### Concluding thoughts and evaluation and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbdd22bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT Metrics: {'exact_match': 14.285714285714286, 'f1': 42.176870748299315}\n",
      "LegalBERT Metrics: {'exact_match': 0.0, 'f1': 6.722689075630251}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation and metrics\n",
    "\n",
    "distil_metrics = evaluate_model(results, \"distil_answer\")\n",
    "legal_metrics = evaluate_model(results, \"legal_answer\")\n",
    "\n",
    "print(\"DistilBERT Metrics:\", distil_metrics)\n",
    "print(\"LegalBERT Metrics:\", legal_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875af8d9",
   "metadata": {},
   "source": [
    "**DistilBERT Metrics**\n",
    "\n",
    "* **Exact Match:** A score of 14.29% of predictions matching exactly the ground truth is low. Looking at the results data frame, only two questions were answered correctly with one response being close to the ground truth but still not correct.\n",
    "* **F1 Score:** A score of 42.18% appears to indicate moderate performance. The model is not perfect in capturing the information correctly.\n",
    "\n",
    "**LEGAL-BERT Metrics**\n",
    "\n",
    "* **Exact Match:** A score of 0% of predictions means the model is struggling to provide the correct answers and may not be suited to the task because no questions were answered correctly.\n",
    "* **F1 Score:** The F1 score is very low also indicating that this model may not be suited to the task.\n",
    "\n",
    "DistilBERT outperforms LEGAL-BERT specifically in both metrics. This may be because the datasets used to train LEGAL-BERT are not similar to the language, formatting, and content present in zoning by-laws. Zoning by-laws may be legal documents, but the content and language appears to be more factual and in varying formats (tables and images besides raw text).\n",
    "\n",
    "Although DistilBERT outperforms LEGAL-BERT, it appears that it is not ideal for this task.  Fine-tuning DistilBERT or exploring alternative methods, such as OCR (optical character recognition), may yield better results. It seems that manually extracting data from the zoning by-law or using the [Claude LLM API Pipeline](https://github.com/JoT8ng/zoning-extraction-pipelines/blob/main/llm_api_pipeline/src/README.md) would be more effective and efficient despite the problem of hallucinations. Perhaps, NLP models are not the solution for zoning by-laws due to their long, complex and varying formats. OCR (optical character recognition) models could potentially be more suitable for automating this task, although the results would similarly have to be double checked. The limitations of OCRs involve accuracy issues with complex PDF layouts or the need for post-processing the data outputs.\n",
    "\n",
    "However, it is important to note that a small dataset was used in this experiment and a larger one might yield more meaninful results. As a starting small test, it is a good starting point but for a more rigorous test a larger dataset would be better. It is also important to consider that this LEGAL-BERT model is not fine-tuned for QA, hence its poor performance.\n",
    "\n",
    "### Lessons Learned and Improvements\n",
    "\n",
    "* Tiny dataset: Seven dataset examples cannot meaningfully measure performance. 50-100 labeled examples with a good balance of answerable and unanswerable questions would be good with diverse question phrasing.\n",
    "* Add negative answer handling/ use models that support \"no answer\".\n",
    "* Experiment with another legal BERT model fine-tuned for QA (although it seems like BERT would be sufficient. Might make more sense to finetune a BERT or DistilBERT model to zoning by-laws instead).\n",
    "* Consider fine-tuning DistilBERT. Using any DistilBERT model, fine-tuned or not, may not be the best solution to this problem because the user would have to feed the model smaller/more specific snippets of text to the model to extract the answer/data they require from the zoning by-law. This is because zoning by-laws are long and to feed it longer snippets of text requires a larger token size than what is currently accepted in any of the BERT models. In this scneario, it may be more efficient for the user to go through the by-law and find the data they require manually themselves.\n",
    "* Compared to fine-tuning a DistilBERT model, consider exploring alternative methods like OCR (optical character recognition). Using an OCR model may be more efficient although the results would have to be double checked and post-processing of the data is required."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
